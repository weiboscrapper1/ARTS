# Algorithem

##[10. Regular Expression Matching](https://github.com/weiboscrapper1/arts_leetcode/blob/master/src/main/java/practice/leetcode/algorithm/RegularExpressionMatching.java)

# Review

[Microservices Logging Best Practices](https://blog.scalyr.com/2018/08/microservices-logging-best-practices/)

[Microservice architecture](http://microservices.io/)是一种应用程序结构，它倡导使用松耦合的系统，使得服务的开发，测试，部署和发布相互独立。这些服务作为一个独特系统的部分，使用这些微服务背后的想法是将一个大问题分解为多个小问题。 通常，每个服务通过HTTP端点和其他服务交互，仅通过向使用者公开调用规约来隐藏其技术堆栈的细节。 服务A调用服务B，同时有调用服务C。一旦调用链完成，服务A就能够反馈给发起请求的最终客户。

微服务架构提供了很多好处，例如能够使用不同的技术堆栈，独立部署，每次解决一个小问题......！ 但是使用微服务的成本很高，因为它们很复杂......不仅在于它们彼此之间如何通信，还在于如何管理它们。 当一个或多个服务失败时，它们会变得更加复杂。 哪个服务失败了？ 为什么？在什么情况下失败了？ 如果没有好的，浅显易懂的日志，这些问题都很难回答。

说实话，我们都讨厌那些“未知”或“出错”的系统错误。 我自己一直在努力解决糟糕的日志策略带来的问题。我来分享一些在处理微服务时帮助我的最佳实践。

## 将请求通过一个唯一的ID关联起来

回想一下在上一节中谈到的服务A，B和C之间的请求调用链。 根据这个想法，使用唯一ID来标记每个调用是一个好习惯。

例如，假设您正在记录每个服务的访问日志和错误日志。 如果在服务B中发现错误，则可能有必要了解错误是由来自服务A的请求引起的，还是发送到服务C的请求引起的。

也许这个错误包含了足够的信息，甚至都不需要去重现它。 但如果不是这种情况，重现错误的正确方法是知道在所有和服务B相关的所有可能请求。当你有关联的请求ID时，您只需要在日志中查找该ID。 你会众多服务中获取所有日志。 你还将知道主要请求花费最多时间是在哪个服务，服务是否使用缓存，服务是否多次调用其他服务，以及许多其他有趣的细节。

## 在回复中包含唯一ID

在微服务中，错误是不可避免的。 不要错过找出导致错误的原因的机会。在有错误发生的时候，应该对客户端收到的回复进行编码，这样以便它包含唯一ID以及该错误的任何其他有用信息。 正如上面所讨论的，这个唯一ID可能与您用来关联请求的ID相同。

在请求的响应有效负载中嵌入唯一ID将帮助您和您的客户更快地发现问题。 您将了解请求的参数，例如日期，时间和其他详细信息。这些参数有助于您更好地了解问题。 除了提供类似“联系服务管理员报告问题”这种常见错误消息，还可以使用标记请求的ID作为补充。 通过这种方式，可以了解导致错误的原因并防止将来再次发生错误。

## 将日志发送到集中位置

假设您已经在日志中添加了各种有用的信息。但是将日志发送到集中位置至关重要。

想一想。如果您需要登录到每个独立的服务器上以读取日志，那么您将花费更多时间来尝试关联问题。如果有一个地方可以访问所有日志，那么所花费的时间则少得多。而且，随着时间的推移，系统通常会变得越来越复杂，所以通常微服务的数量也会增长。另外，服务可以托管在不同的服务器或提供商上，这也使事情变得更加复杂，。

集中式日志记录正在成为常态。特别是如果您正在使用云，容器或混合环境的时候，这点显得尤其突出，因为服务器可以在没有任何通知的情况下宕机。例如，有意外错误发生，或者内存达到其消耗容量的100％，容器将被终止。

您可以通过让代理每隔五分钟或在服务器终止之前推拉日志来解决这个问题。您还可以在服务器，边车容器或共享文件位置中配置cronjob，其他进程可以集中日志。避免自己构建解决方案堆栈，因为日志集中化是众所周知的问题，已经得到了解决。

将所有服务的日志放在一个地方可以让关联问题变得轻松高效。

## 构建您的日志数据

为日志数据定义格式几乎是不可能的。某些日志可能需要比其他日志更多的字段，而那些不需要所有这些多余字段的日志将会浪费磁盘空间。微服务架构通过使用不同的技术堆栈来解决这个问题，这会影响每个服务的日志格式。一个服务可能使用逗号作为分隔符，而其他服务使用竖线或空格。

所有这一切都变得非常复杂。通过将日志数据结构化为JavaScript Object Notation（JSON）等标准格式，使解析日志的过程更加简单。 JSON允许您为数据创建多个级别，以便在必要时，您可以在单个日志事件中获得更多语义信息。

解析也比处理特定的日志格式更直接。对于结构化数据，日志的格式是标准的，即使日志可能具有不同的字段。您还可以在集中位置创建搜索，例如查找“http_code”为500及以上的日志。使用结构化日志在您的微服务日志中具有标准但灵活的格式。

## 为每个请求添加上下文

当出现问题时，我想知道所有信息！这些信息可为您提供请求的重要的上下文。了解可能导致问题的原因至关重要，拥有正确的上下文将有助于您更快地了解正在发生的事情。但是向日志添加上下文可能会成为代码中的重复任务，因为在每个日志事件中都会有日常和时间等常见数据。因此在代码中，日志记录看起来会更简单，因为您只会记录消息和其他独特区域。

您可能希望记录您可以获得的所有数据。但是，让我给你一些特定的字段，可以帮助你弄清楚你真正需要记录的内容。

- 日期和时间。对于需要查看日志的人而言，只要时区都是相同的，它就不必是UTC。
- 堆栈错误。您可以将异常对象作为参数传递给日志记录库。
- 服务名称或代码，以便您可以区分哪些日志来自哪个微服务。
- 发生错误的函数，类或文件名，这样您就不必猜测问题所在。
- 外部服务交互名称 - 您将知道哪个DB调用是有问题的。
- 服务器和客户端请求的IP地址。该信息可以轻松发现不健康的服务器或识别DDoS攻击。
- 应用程序的用户代理，以便您了解哪些浏览器或用户遇到问题。
- HTTP代码以获得更多错误的语义。这些代码对于创建警报很有用。

当需要在系统中进行故障排除时候，为请求添加上下文，并将它们记录到日志中，这些操作能够节省时间。

## 将日志写入本地存储

将日志写入本地存储，这听起来与我之前所说的将日志发送到集中位置的内容相矛盾，但耐心点，听我说完。第一次了解到日志集中化后，我决定直接通过HTTP请求发送日志。这主意不坏，但也不是一个好主意。有时候出站网络流量太大，这严重影响了对其他更重要的微服务的调用。

将日志发送到本地存储时总会有权衡。但我更喜欢这个选项，因为它有助于解耦日志记录和减少应用程序内的上下文切换。您可能希望将用于日志的存储卷与用于应用程序的存储卷分开，特别是该应用程序是数据库的时候。例如，亚马逊网络服务（AWS）可以选择使用名为弹性文件系统（EFS）的服务来安装卷，该服务的作用类似于网络附加存储（NAS）。您可以启动另一台服务器，在其中加载相同的卷，然后将日志转发到集中位置。

将应用程序的所有日志发送到同一位置，这样让事情保持简单，使用Docker容器可以促进此行为。将聚合，过滤和转发日志的责任转移到一些其他流程或服务。

## 记录有用和有意义的数据以避免后悔
这些只是一些帮助您记录微服务的常见做法。如果您刚刚开始使用日志，这些做法可能没有多大意义，似乎毫无用处。但是，一旦你使用微服务一段时间，日志将为你省去很多麻烦。只需确保您经常评估您正在记录的内容。当你进行故障排除时，问问自己“我希望我有X和Y信息，这样我就能更容易地发现这些奇怪的错误。”，你会更好地了解哪些内容足够重要需要记录下来。

一旦您记录了足够的数据，就可以执行警报等自动操作。您不必花费大量时间阅读日志来发现问题。自动化警报还可以帮助您积极主动，并防止错误在所有用户中蔓延开来。

对微服务而言，将日志集中化以便进一步分析是必须的。为日志添加足够的上下文将有助于识别哪些日志数据有用，哪些数据无用。


# Tips

## [progress](https://github.com/Xfennec/progress): 显示Linux命令执行进度的工具

1. progress只能显示以下命令的执行进度

   `cp, mv, dd, tar, cat, rsync, grep, fgrep, egrep, cut, sort, md5sum, sha1sum, sha224sum, sha256sum, sha384sum, sha512sum, adb, gzip, gunzip, bzip2, bunzip2, xz, unxz, lzma, unlzma, 7z, 7za, zcat, bzcat, lzcat, split, gpg`

2. 工作原理

   progress首先搜索/proc，查找要监控的命令，然后搜索`fd`和`fdinfo`目录，找到打开的文件，计算执行进度。

# Share

## [15.8.3.4 配置InnoDB缓冲池预取（预读）](https://dev.mysql.com/doc/refman/8.0/en/innodb-performance-read_ahead.html)

[预读请求](https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_read_ahead)是一个I/O请求，如果预计一些页面很快就会被使用，就以异步的方式，从缓冲池中预先取出这些页面。 这些请求将获取`一定范围`([extent](https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_extent))内的所有页面。`InnoDB`使用两种预读算法来提高I/O性能：


线性(**Linear**)预读这项技术是根据缓冲池中页面的顺序，预测哪些页面将很快被访问。通过使用配置参数[`innodb_read_ahead_threshold`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_read_ahead_threshold)调整触发异步读取请求所需的连续页面访问次数，可以控制InnoDB何时执行预读操作。 在添加此参数之前，当读取当前范围的最后一页的时候，InnoDB只计算是否对整个下一个范围发出异步预取请求。

配置参数[`innodb_read_ahead_threshold`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_read_ahead_threshold) 用于控制InnoDB在检测连续页面访问模式方面的敏感程度。 如果从某个范围顺序读取的页数大于或等于[`innodb_read_ahead_threshold`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_read_ahead_threshold) ，则InnoDB会启动整个后续范围的异步预读操作。[`innodb_read_ahead_threshold`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_read_ahead_threshold) 可以设置为0-64之间的任何值。 缺省值是56。设置的值越高，访问模式检查越严格。 例如，如果将值设置为48，InnoDB只有在当前范围中的48页已被顺序访问时才会触发线性预读请求。 如果值为8，则即使连续访问范围内的最少8页，InnoDB也会触发异步预读。 您可以在MySQL配置文件中设置此参数的值，或者用SET GLOBAL命令动态更改该参数的值，但是后者需要足够的权限以设置全局变量。


随机(**Random**)预读这项技术是根据缓冲池中已有的页面预测哪些页面将很快被访问，而不管这些页面的读取顺序如何。 如果在缓冲池中找到来自相同范围的连续13个页面，则InnoDB会发出一个异步请求以预取该范围内剩余页面。 要启用此功能，请将配置变量[`innodb_random_read_ahead`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_random_read_ahead)设置为ON。

`SHOW ENGINE INNODB STATUS`命令显示统计信息，以帮助您评估预读算法的有效性。 统计数据包括以下全局状态变量的计数器信息：

- [`Innodb_buffer_pool_read_ahead`](https://dev.mysql.com/doc/refman/8.0/en/server-status-variables.html#statvar_Innodb_buffer_pool_read_ahead)
- [`Innodb_buffer_pool_read_ahead_evicted`](https://dev.mysql.com/doc/refman/8.0/en/server-status-variables.html#statvar_Innodb_buffer_pool_read_ahead_evicted)
- [`Innodb_buffer_pool_read_ahead_rnd`](https://dev.mysql.com/doc/refman/8.0/en/server-status-variables.html#statvar_Innodb_buffer_pool_read_ahead_rnd)

这些信息在微调[`innodb_random_read_ahead`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_random_read_ahead)设置时非常有用。